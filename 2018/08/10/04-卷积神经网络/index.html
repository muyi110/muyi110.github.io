<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Times New Roman:300,300italic,400,400italic,700,700italic|18:300,300italic,400,400italic,700,700italic|Courier New:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hello, World" />










<meta name="description" content="卷积神经网络基础计算机视觉计算机视觉 ( Computer Vision )是一个飞速发展的领域，其中深度学习技术起到重要作用。计算机视觉中有许多的应用，例如图片分类 ( Image Classification ) 、目标检测 ( Object detection ) 、图片风格转换 ( Neural Style Transfer ) 等等。应用计算机视觉时可能要面临的一个挑战是输入的数据">
<meta property="og:type" content="article">
<meta property="og:title" content="04.卷积神经网络">
<meta property="og:url" content="https://muyi110.github.io/2018/08/10/04-卷积神经网络/index.html">
<meta property="og:site_name" content="MuYi&#39;s Blog">
<meta property="og:description" content="卷积神经网络基础计算机视觉计算机视觉 ( Computer Vision )是一个飞速发展的领域，其中深度学习技术起到重要作用。计算机视觉中有许多的应用，例如图片分类 ( Image Classification ) 、目标检测 ( Object detection ) 、图片风格转换 ( Neural Style Transfer ) 等等。应用计算机视觉时可能要面临的一个挑战是输入的数据">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_052.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_053.png">
<meta property="og:image" content="https://muyi110.github.io/images/Convolution_schematic.gif">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_054.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_055.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_056.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_057.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_058.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_059.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_060.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_061.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_062.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_063.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_064.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_065.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_066.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_067.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_068.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_069.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_070.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_071.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_072.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_073.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_074.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_075.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_076.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_077.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_078.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_079.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_080.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_081.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_082.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_083.png">
<meta property="og:image" content="https://muyi110.github.io/images/deeplearning_ai_084.png">
<meta property="og:updated_time" content="2018-08-11T12:17:52.774Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="04.卷积神经网络">
<meta name="twitter:description" content="卷积神经网络基础计算机视觉计算机视觉 ( Computer Vision )是一个飞速发展的领域，其中深度学习技术起到重要作用。计算机视觉中有许多的应用，例如图片分类 ( Image Classification ) 、目标检测 ( Object detection ) 、图片风格转换 ( Neural Style Transfer ) 等等。应用计算机视觉时可能要面临的一个挑战是输入的数据">
<meta name="twitter:image" content="https://muyi110.github.io/images/deeplearning_ai_052.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://muyi110.github.io/2018/08/10/04-卷积神经网络/"/>





  <title>04.卷积神经网络 | MuYi's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">MuYi's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">此博客创建于2018-07-10</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-reprinted_article">
          <a href="/reprinted-article/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heart"></i> <br />
            
            转载文章
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://muyi110.github.io/2018/08/10/04-卷积神经网络/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="穆义">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/wukong.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MuYi's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">04.卷积神经网络</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-10T15:25:02+08:00">
                2018-08-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习课程-Andrew-Ng-学习笔记/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习课程(Andrew Ng)学习笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<h1 id="卷积神经网络基础"><a href="#卷积神经网络基础" class="headerlink" title="卷积神经网络基础"></a>卷积神经网络基础</h1><h2 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h2><p>计算机视觉 ( <code>Computer Vision</code> )是一个飞速发展的领域，其中深度学习技术起到重要作用。计算机视觉中有许多的应用，例如图片分类 ( <code>Image Classification</code> ) 、目标检测 ( <code>Object detection</code> ) 、图片风格转换 ( <code>Neural Style Transfer</code> ) 等等。<br>应用计算机视觉时可能要面临的一个挑战是<strong>输入的数据可能会非常大</strong>。例如输入一张 \(1000\times 1000\times 3 \) 的图片，则神经网络的输入维度将达到 300 万，使得神经网络的权重 \(W\) 的参数非常多，会带来两个后果：</p>
<ol>
<li>难以获得足够数据来防止神经网络发生过拟合；</li>
<li>需要很大的内存和计算代价。</li>
</ol>
<p>因此，需要利用<strong>卷积神经网络</strong> ( <code>Convolutional Neural Network, CNN</code> )。</p>
<h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><blockquote>
<p>卷积运算 (<code>Convolutional Operation</code>) 是卷积神经网络最基本的组成部分。（神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（例如眼睛、鼻子等）、到最后一层可由前面检测的特征识别整体面部轮廓。）</p>
</blockquote>
<p>图片常做的边缘检测有<strong>垂直边缘检测</strong>和<strong>水平边缘检测</strong>等，如下图所示。<img src="/images/deeplearning_ai_052.png" alt="边缘检测">图片的边缘检测可以通过与相应滤波器卷积来实现。例如在垂直边缘检测中，原始图片是 \(6\times 6 \) ，中间的矩阵称为<strong>滤波器</strong> (<code>filter</code>) ，大小为 \(3\times 3 \) ，卷积后的图片大小为 \(4\times 4\) ，如下图所示（以左上角和右下角为例，数值表示灰度）：<img src="/images/deeplearning_ai_053.png" alt="垂直边缘检测卷积运算">根据上图可知，卷积运算过程为从左到右，从上到下，每次在原始图中取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘（逐元素相乘）然后求和，将结果组成一个新的矩阵输出，为方便理解，下图是卷积运算实现动图：<img src="/images/Convolution_schematic.gif" alt="卷积运算实现动图">下图是垂直边缘检测的另一个例子，解释为什么下图中的滤波器可以做垂直边缘检测：<img src="/images/deeplearning_ai_054.png" alt="垂直边缘检测解释">将上图中最右边的矩阵看作输出图片，则经过卷积后，输出图片中间白色区域对应输入图片中间的垂直边缘（区分白色和灰色的垂直线）。</p>
<h2 id="更多边缘检测例子"><a href="#更多边缘检测例子" class="headerlink" title="更多边缘检测例子"></a>更多边缘检测例子</h2><p><img src="/images/deeplearning_ai_055.png" alt="边缘检测又例">如果将灰度图左右数值进行翻转，再与之前的滤波器进行卷积，得到结果有区别。实际中，反映了由明变暗和由暗变明的两种渐变方式。如果不在乎两者的区别，可以对输出取绝对值。<br>下图是垂直边缘检测和水平边缘检测滤波器：<img src="/images/deeplearning_ai_056.png" alt="垂直和水平边缘检测">还有其他的滤波器，如 <code>Sobel</code> 滤波器和 <code>Scharr</code> 滤波器，其增加了中间一行的权重，提高了结果的稳健性。<img src="/images/deeplearning_ai_057.png" alt="其它滤波器示例"><strong>注意</strong>：实际中，不一定去使用那些研究者选择的滤波器数字，<strong>可以将滤波器中的数字看成参数</strong>，之后可以通过反向传播去学习这些参数。</p>
<h2 id="填充-Padding"><a href="#填充-Padding" class="headerlink" title="填充 ( Padding )"></a>填充 ( Padding )</h2><p>假如输入的图片大小是 \(n\times n \) 滤波器的大小是 \(f\times f \) ，则卷积后的输出大小是 \((n-f+1)\times (n-f+1)\) 。这样会存在两个缺点：</p>
<ol>
<li>每次卷积运算后，输出的图形会缩小，例如从 \(6\times 6 \) 缩小到 \(4\times 4 \)，经过几次后可能变为 \(1\times 1 \) 的大小。</li>
<li>那些在角落或者边缘区域的像素在输出中采用较少，意味着丢掉了图像边缘位置的许多信息。</li>
</ol>
<p>为了解决这两个问题，需要在卷积操作之前对输入图像进行<strong>填充</strong>。就是在图像边缘再填充像素，<strong>通常填充 \(0\)</strong> 。如果用 <code>p</code> 表示每个方向填充的像素点的数量，下图的中 \(p=2 \) ：<img src="/images/deeplearning_ai_058.png" alt="填充事例">可知，填充后的图片大小是 \((n+2p)\times (n+2p)\) ，滤波器的大小是 \(f\times f \) ，则卷积后输出大小是 \((n+2p-f+1)\times (n+2p-f+1)\) 。<br>至于选择多少像素填充，有两种选择：</p>
<ul>
<li><strong>Valid 填充</strong>：不填充( \(p=0 \) )，输出结果是 \((n-f+1)\times (n-f+1)\) 。</li>
<li><strong>Same 填充</strong>：填充使得输入和卷积后的输出的大小一样，需要 \(p=\dfrac {f-1}{2}\) 。</li>
</ul>
<p><strong>注意</strong>：一般情况下，\(f\) 通常是奇数。</p>
<h2 id="卷积步长-Strided-convolutions"><a href="#卷积步长-Strided-convolutions" class="headerlink" title="卷积步长 ( Strided convolutions )"></a>卷积步长 ( Strided convolutions )</h2><blockquote>
<p>卷积步长是另一个构建卷积神经网络的基本操作。</p>
</blockquote>
<p><strong>步长表示滤波器在原始图像上水平或垂直方向上每次移动的距离。</strong>之前的步常默认为 \(1\) 。如果将步长设置为 \(2\) 则卷积过程如下图所示：<img src="/images/deeplearning_ai_059.png" alt="步长为2的卷积过程">设步长为 s ，填充像素量为 p ，输入图片大小为 \(n\times n \) ，滤波器大小为 \(f\times f \) ，则卷积后的输出大小为：$$\lfloor {\dfrac {n+2p-f}{s}+1}\rfloor \times \lfloor {\dfrac {n+2p-f}{s}+1}\rfloor$$公式中的符号表示取整符号。</p>
<ul>
<li>杂谈：<blockquote>
<p>在机器学习中谈论的<strong>卷积</strong>实际上被称为<strong>互相关 (cross-correlation)</strong>，不是数学意义上的卷积。数学上的卷积在做元素乘积求和之前，需要将滤波器沿水平和垂直轴翻转（相当于做镜像）。但按照机器学习惯例，通常不进行翻转操作。</p>
</blockquote>
</li>
</ul>
<h2 id="高维卷积"><a href="#高维卷积" class="headerlink" title="高维卷积"></a>高维卷积</h2><p><img src="/images/deeplearning_ai_060.png" alt="三通道卷积"><strong>如果对三通道的 <code>RGB</code> 的图像 (\(6\times 6 \times 3 \)) 进行卷积操作，则对应的滤波器也同样是三通道的 (\(3\times 3\times 3 \))卷积的结果输出是 (\(4\times 4 \times 1\))</strong>。实现过程：将每个单通道与对应的滤波器（单通道）进行卷积，然后将三个通道相加，将 \(27\) 个值求和作为一个输出值。<br>不同的通道对应的滤波器可以不同。例如，如果只检测 <code>R</code> 通道的垂直边缘，则 <code>G</code> 和 <code>B</code> 通道对应的滤波器值可以全部设置为 \(0\) 。<strong>当输入有特定的高度、宽度和通道数时，滤波器可以有不同的高、宽，但必须有相同的通道数。</strong><br>如果想同时检测垂直和水平边缘，或更多其他边缘（换句话说就是同时检测更多特征），可以增加滤波器个数。例如设置第一个滤波器检测垂直边缘，第二个滤波器检测水平边缘，最后将每个滤波器卷积的输出堆叠在一起，如下图所示：<img src="/images/deeplearning_ai_061.png" alt="多个滤波器">每个滤波器的输出对应一个特征。设输入的图像大小是 \(n\times n \times n_c\) (\(n_c \) 是通道数) ，滤波器大小是 \(f\times f \times n_c \) ，则卷积的输出是 \((n-f+1)\times (n-f+1)\times n’ _c \) ，其中 \(n’_c \) 为滤波器个数（默认步长为 \(1\)）。</p>
<h2 id="单层卷积网络-one-layer-of-a-convolutional-network"><a href="#单层卷积网络-one-layer-of-a-convolutional-network" class="headerlink" title="单层卷积网络 (one layer of a convolutional network)"></a>单层卷积网络 (one layer of a convolutional network)</h2><p><img src="/images/deeplearning_ai_062.png" alt="单层卷积网络">与之前的卷积过程相比较，卷积神经网络的单层结构多了<strong>激活函数</strong>和<strong>偏移量</strong>；而与标准神经网络：$$Z ^{[l]} = W ^{[l]}A ^{[l-1]}+ b$$$$A ^{[l]}= g ^{[l]}(Z ^{[l]})$$相比，滤波器的数值对应权重 \(W ^{[l]}\) ，卷积运算对应 \(W ^{[l]}\) 与 \(A ^{[l-1]}\) 的乘积运算，激活函数选择 <code>Relu</code> 函数。<br>下面视频说明了单层卷积神经网络工作过程：</p>
<p><div align="center"><video width="620" height="440" src="/images/conv_kiank.mp4" type="video/mp4" controls><br></video></div><br>对于一个 \(3\times 3 \times 3 \) 的滤波器，包括偏移量 \(b\) 在内共有 \(28\) 个参数，不论输入的图像多大，参数始终是 \(28\) 。即<strong>选定滤波器组后，参数的数目与输入的图片尺寸无关</strong>，因此对比标志神经网络，卷积神经网络的参数要少的多，这是卷积神经网络 (<code>CNN</code>) 的优点之一。<br><strong>符号总结</strong><br>设 \(l\) 层为卷积层，则：</p>
<ul>
<li>\(f ^{[l]}\) ：滤波器的高或宽；</li>
<li>\(p ^{[l]}\) ：填充的像素数量；</li>
<li>\(s ^{[l]}\) ：步长；</li>
<li>\(n _c ^{[l]}\) ：滤波器的个数；</li>
<li>输入维度：\(n _H ^{[l-1]}\times n _W ^{[l-1]}\times n _c ^{[l-1]}\) ，其中 \(n _H ^{[l-1]}\) 表示输入图像高度，\(n _W ^{[l-1]}\) 表示输入图像宽度。</li>
<li>输出维度：\(n _H ^{[l]}\times n _W ^{[l]}\times n _c ^{[l]}\) ，其中：$$n _H ^{[l]} = \lfloor {\dfrac {n _H ^{[l-1]}+2p ^{[l]}-f ^{[l]}}{s ^{[l]}}+1}\rfloor$$$$n _W ^{[l]} = \lfloor {\dfrac {n _W ^{[l-1]}+2p ^{[l]}-f ^{[l]}}{s ^{[l]}}+1}\rfloor$$</li>
<li>每个滤波器的维度是：\(f ^{[l]}\times f ^{[l]}\times n _c ^{[l-1]}\) ，其中 \(n _c ^{[l-1]}\) 为输入图像的通道数（也称为深度）；</li>
<li>权重维度：\(f ^{[l]}\times f ^{[l]}\times n _c ^{[l-1]}\times n _c ^{[l]}\) ；</li>
<li>偏置维度：\(1\times 1 \times 1 \times n _c ^{[l]}\)。</li>
</ul>
<p>注：不同的文献可能对高度、宽度、通道数的顺序表示不同。</p>
<h2 id="简单卷积网络示例"><a href="#简单卷积网络示例" class="headerlink" title="简单卷积网络示例"></a>简单卷积网络示例</h2><p>一个简单的 <code>CNN</code> 神经网络如下图所示：<img src="/images/deeplearning_ai_063.png" alt="简单CNN神经网络">图中 \(a ^{[3]}\) 的维度为 \(7\times 7 \times 40 \) ，将 \(1960\) 个特征拉伸为一列，作为最后一层的输入。<br>随着神经网络的深度的不断加深，输出的图像的高度 \(n _H ^{[l]}\) 和宽度 \(n _W ^{[l]}\) 不断减小，但 \(n _c ^{[l]}\)在不断增加。<br>一个典型的卷积神经网络通常有三种层：<strong>卷积层 (Convolution layer)、池化层 (Pooling layer) 、全连接层 (Fully Connected layer)</strong>。</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><blockquote>
<p><strong>池化层可用来缩减模型大小、提高计算速度、同时提高所提取特征的鲁棒性。</strong></p>
</blockquote>
<p>实际中，采用较多的一种池化过程叫<strong>最大化池化 (Max Pooling)</strong>。将输入拆分为不同的区域，输出的每个元素都是对应区域的最大值，如下图所示：<img src="/images/deeplearning_ai_064.png" alt="最大池化">池化过程类似于卷积过程，上图中的池化过程相当于使用了大小 \(f=2\) 的滤波器，且步长为 \(s=2\) 。卷积过程的公式同样也适用于池化过程。<strong>如果输入有多个通道，则分别对每个通道执行池化过程</strong>，因此输入的通道数和输出的通道数一样。</p>
<ul>
<li>杂谈：最大池化过程的直观理解<blockquote>
<p>元素值较大可能意味着池化过程之前的卷积过程提取到了某些特定的特征，池化过程中的最大化操作使得只要在一个区域内提取到某个特征，它都会保留在最大池化的输出中。</p>
</blockquote>
</li>
</ul>
<p>另一种池化过程是<strong>平均池化 (Average Pooling)</strong>。将从取某个区域最大值改为取这个区域的平均值作为输出（用的较少）。平均池化过程如下图所示：<img src="/images/deeplearning_ai_065.png" alt="平均池化"><strong>注意</strong>：池化过程有一组超参数（大小 \(f\) ，步长 \(s\) ，及选择最大池化还是平均池化）但<strong>没有参数需要学习</strong>。填充参数 \(p\) 很少用。<br>池化过程的输入维度为：$$n _H\times n _W\times n _c$$输出维度为：$$\lfloor {\dfrac {n _H -f}{s}+1}\rfloor \times \lfloor {\dfrac {n _W -f}{s}+1}\rfloor\times n _c$$</p>
<h2 id="卷积神经网络示例"><a href="#卷积神经网络示例" class="headerlink" title="卷积神经网络示例"></a>卷积神经网络示例</h2><p>下图是一个识别数字的卷积神经网络的结构（类似 <code>LeNet-5</code> 网络）：<img src="/images/deeplearning_ai_066.png" alt="识别数字CNN">建议：计算神经网络的层数时，通常只统计具有权重和参数的层，因此池化层和之前的卷积层记为一层。<br>图中的 <code>FC3</code> 和 <code>FC4</code> 为全连接层，与标准的神经网络一致。整个神经网络的参数如下图所示：<img src="/images/deeplearning_ai_067.png" alt="CNN 参数"></p>
<h2 id="使用卷积神经网络原因"><a href="#使用卷积神经网络原因" class="headerlink" title="使用卷积神经网络原因"></a>使用卷积神经网络原因</h2><p>和标准神经网络对比，对于大量的输入数据，<code>CNN</code> 有效减小了参数的数量，原因如下：</p>
<ul>
<li><strong>参数共享 (Parameter sharing)</strong>：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。</li>
<li><strong>稀疏连接 (Sparsity of connections)</strong>：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。</li>
</ul>
<p><strong>池化过程则在卷积后很好地聚合了特征，通过降维来减少运算量。</strong><br>由于 <code>CNN</code> 参数数量较小，所需的训练样本就相对较少，因此在一定程度上不容易发生过拟合现象。并且 <code>CNN</code> 比较擅长捕捉区域位置偏移（捕捉平移不变）。即进行物体检测时，不太受物体在图片中位置的影响，增加检测的准确性和系统的健壮性。</p>
<h1 id="深度卷积网络：实例探究"><a href="#深度卷积网络：实例探究" class="headerlink" title="深度卷积网络：实例探究"></a>深度卷积网络：实例探究</h1><p>本节涉及的神经网络实例包括：</p>
<ul>
<li>LeNet-5</li>
<li>AlexNet</li>
<li>VGG</li>
</ul>
<p>此外还涉及 Resnet (Residual Network, 残差网络) 和 Inception Neural Network 。</p>
<h2 id="经典网络"><a href="#经典网络" class="headerlink" title="经典网络"></a>经典网络</h2><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p><img src="/images/deeplearning_ai_068.png" alt="LeNet-5">该网络具有的特点如下：</p>
<ul>
<li><code>LeNet-5</code> 针对灰度图像训练，输入图像的通道数为 \(1\) ；</li>
<li>该网络模型包含参数少（此例中大约 \(6\) 万个），远少于现代神经网络的参数；</li>
<li>针对分类问题，现代版本中输出层使用 <code>Softmax</code> 函数（图中含有 \(84\) 个节点的层作为 <code>Softmax</code> 的输入；</li>
<li>该网络包含一种模式至今常用到，就是<strong>一个或多个卷积层后跟着一个池化层，然后又是若干个卷积层再接一个池化层，然后是全连接层，最后是输出</strong>；</li>
<li><code>LeNet-5</code> 网络被提出时，其池化层使用平均池化，各层的激活函数一般选择 <code>Sigmoid</code> 和 <code>tanh</code> 。现在，根据需要可以做出改进，例如使用最大池化，激活函数选择 <code>Relu</code> 函数。</li>
</ul>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p><img src="/images/deeplearning_ai_069.png" alt="AlexNet">该网络具有的特点如下：</p>
<ul>
<li><code>AlexNet</code> 模型与 <code>LeNet-5</code> 模型类似，但更加复杂（此例中包含大约 \(6000\) 万个参数。 <code>AlexNet</code> 模型使用了 <code>Relu</code> 激活函数；</li>
<li>当用于训练图像和数据集时， <code>AlexNet</code> 网络结构能够处理非常相似的基本构造块，这些模块往往包含大量的隐藏单元或数据。</li>
</ul>
<p>相关论文参考：<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks</a></p>
<h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p><img src="/images/deeplearning_ai_070.png" alt="VGG">该网络具有的特点如下：</p>
<ul>
<li><code>VGG</code> 又称为 <code>VGG-16</code> ，其中数字 \(16\) 表示网络中包含 \(16\) 个卷积层和全连接层；</li>
<li>结构不复杂且规整（都是几个卷积层后面跟着可以压缩图像大小的池化层），卷积层的滤波器数量在每一步翻倍，或者说在每一组卷积层进行过滤器翻倍操作。</li>
<li>主要缺点是需要训练的特征数量非常大。</li>
</ul>
<p>相关论文参考：<a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">Simonvan &amp; Zisserman 2015. Very deep convolutional networks for large-scale image recognition</a></p>
<h2 id="残差网络-Residual-Networks-ResNets"><a href="#残差网络-Residual-Networks-ResNets" class="headerlink" title="残差网络 (Residual Networks, ResNets)"></a>残差网络 (Residual Networks, ResNets)</h2><blockquote>
<p>The main benefit of a very deep network is that it can represent very complex functions. It can also learn features at many different levels of abstraction, from edges (at the lower layers) to very complex features (at the deeper layers). However, using a deeper network doesn’t always help. A huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent unbearably slow. More specifically, during gradient descent, as you backprop from the final layer back to the first layer, you are multiplying by the weight matrix on each step, and thus the gradient can decrease exponentially quickly to zero (or, in rare cases, grow exponentially quickly and “explode” to take very large values). </p>
</blockquote>
<p>由于存在梯度消失和梯度爆炸问题，很深的网络往往很难训练。<strong>残差网络 (ResNets)</strong>可有效解决这个问题。<br><img src="/images/deeplearning_ai_071.png" alt="残差块">上图是<strong>残差块 (Residual block)</strong>。通过<strong>捷径</strong> ( <code>Short cut</code>，或者称为 <code>Skip connections</code> 跳远连接)将 \(a ^{[l]}\) 添加到第二个 <code>Relu</code> 中，直接建立 \(a ^{[l]}\) 和 \(a ^{[l+2]}\) 的连接。对应的表达式如下：$$z ^{[l+1]}=W ^{[l+1]}a ^{[l]}+b ^{[l+1]}$$$$a ^{[l+1]}=g(z ^{[l+1]})$$$$z ^{[l+2]}=W ^{[l+2]}a ^{[l+1]}+b ^{[l+2]}$$$$a ^{[l+2]}=g(z ^{[l+2]}+a ^{[l]})$$构建一个残差网络就是将许多残差块堆叠在一起，形成一个很深的网络，如下图所示：<img src="/images/deeplearning_ai_072.png" alt="残差网络">理论上，随着网络深度的加深，性能应该越来越好。但实际中，一个普通网络，随着神经网络层数增加，训练误差会先下降后上升。残差网络在训练集上会表现越来越好。如下图所示：<img src="/images/deeplearning_ai_073.png" alt="误差分析"><strong>残差网络有助于解决梯度消失和梯度爆炸问题</strong>,让我们在训练更深网络的同时，又能保证良好的性能。</p>
<h2 id="残差网络有效的原因"><a href="#残差网络有效的原因" class="headerlink" title="残差网络有效的原因"></a>残差网络有效的原因</h2><p>假设有一个大型神经网络，输入是 X ，输出是 \(a ^{[l]}\) 。给这个神经网络添加额外的两层，输出为 \(a ^{[l+2]}\) 。将这两层看层一个残差块，为便于说明，假设整个网络使用 <code>Relu</code> 激活函数。<img src="/images/deeplearning_ai_074.png" alt="解释残差网络">根据上图有：$$\begin {align} a ^{[l+2]} &amp;=g(z ^{[l+2]}+a ^{[l]})\\&amp;= g(W ^{[l+2]}a ^{[l+1]}+ b ^{[l+2]}+ a ^{[l]}) \end {align}$$当发生梯度消失时，有 \(W ^{[l+2]}\approx 0\) 方便说明令 \(b ^{[l+2]}\approx 0\) 则有：$$a ^{[l+2]}=g(a ^{[l]})=\text {Relu}(a ^{[l]})= a ^{[l]}$$说明增加的两层至少不会降低神经网络的性能（不论是把残差块添加到神经网络的中间还是末端位置）。如果增加的两层隐藏单元学习到了一些有用的信息，则可能会使网络的表现进一步提高。<br>如果 \(a ^{[l]}\) 和 \(a ^{[l+2]}\) 的维度不同，需要引入矩阵 \(W _s \) 与 \(a ^{[l]}\) 相乘，使得二者的维度相同。矩阵 \(W _s \) 可以是模型学习得到，或者是一个固定矩阵，使得 \(a ^{[l]}\) 截断或补 \(0\) 。下图是论文中的残差网络的一个典型结构：<img src="/images/deeplearning_ai_075.png" alt="残差网络用于图像识别">卷积层通常使用 <code>same</code> 卷积以保持维度相同。<br>相关论文：<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">He et al., 2015. Deep residual networks for image recognition</a></p>
<h2 id="1-times-1-卷积"><a href="#1-times-1-卷积" class="headerlink" title="\(1\times 1\) 卷积"></a>\(1\times 1\) 卷积</h2><p>\(1\times 1\) 卷积（或者称为 <code>Network in Network</code>）指滤波器的大小为 \(1\) 。当输入通道为 \(1\) 时，\(1\times 1\)卷积意味着乘积操作（似乎没啥用）。如下图所示：<img src="/images/deeplearning_ai_076.png" alt="1*1卷积">当输入通道数更多时，例如下图中的 \(32\) 个通道，<strong>\(1\times 1\) 卷积可以从根本上理解对这 \(32\) 个不同位置都应用一个全连接层。</strong>可用于降低或升高数据的维度（取决于滤波器的个数）。<img src="/images/deeplearning_ai_077.png" alt="多通道1*1卷积"><strong>池化层可以压缩输入的高度 (\(n _H\)) 和宽度 (\(n _W\))，而 \(1\times 1\) 卷积可以压缩输入的通道数 (\(n _c\))，取决于用多少个滤波器。</strong>例如下图中用 \(32\) 个大小为 \(1\times 1\times 192\) 的滤波器进行卷积，将输入数据通道数从 \(192\) 压缩为 \(32\) 。<img src="/images/deeplearning_ai_078.png" alt="1*1卷积压缩例子"></p>
<h2 id="Inception-网络"><a href="#Inception-网络" class="headerlink" title="Inception 网络"></a>Inception 网络</h2><blockquote>
<p><code>Inception</code> 网络不需要人为决定使用哪种滤波器 (\(1\times 1\) 还是 \(3\times 3\)等) 或者是否需要池化，而是由网络自行确定这些参数，可以给网络添加这些参数的所有可能值，然后将这些对应的输出连接起来，让网络自己学习它需要什么样的参数，采用哪些滤波器组合。</p>
</blockquote>
<p><img src="/images/deeplearning_ai_079.png" alt="Inception网络">为了使得输出组合时维度匹配，<code>Inception</code> 网络选择不同大小的滤波器进行 <code>same</code> 卷积。<br>在提升性能的同时， <code>Inception</code> 网络有较大的计算成本问题，下面以 \(5\times 5\) 大小的卷积为例说明：<img src="/images/deeplearning_ai_080.png" alt="Inception网络计算成本">图中有 \(32\) 个滤波器，每个滤波器大小为 \(5\times 5 \times 192\) ，输出大小为 \(28\times 28\times 32\) ,因此需要计算 \(28\times 28\times 32\) 个数字，对于每个数字，需要执行 \(5\times 5\times 192\) 次乘法，加法和乘法运算次数近似相等。因此，此层的计算量为 \(28\times 28\times 32\times 5\times 5\times 192 =1.2\) 亿。<br>为了解决计算量大的问题，引入 \(1\times 1\) 卷积（有时候称为瓶颈层），如下图：<img src="/images/deeplearning_ai_081.png" alt="有1*1卷积的Inception网络">同理可以计算出引入 \(1\times 1\) 卷积后，计算量变为 \(1024\) 万，大大降低了计算量。<br><strong>注</strong>：只要合理构建瓶颈层，既可以显著缩小表示层规模，又不会降低网络性能，从而节省计算。</p>
<h2 id="完整的-Inception-网络"><a href="#完整的-Inception-网络" class="headerlink" title="完整的 Inception 网络"></a>完整的 Inception 网络</h2><p>下图是引入 \(1\times 1\) 卷积后的 <code>Inception</code> 模块：<img src="/images/deeplearning_ai_082.png" alt="完整的Inception网络模块">使用 <code>same</code> 类型的 <code>padding</code> 来池化，使得输出的高度和宽度和输入保持一致。由于池化层不改变输入的通道数，因此需要加一个 \(1\times 1\) 卷积层将输入通道压缩。<br>多个 <code>Inception</code> 模块组成一个完整的 <code>Inception</code> 网络，如下图所示：<img src="/images/deeplearning_ai_083.png" alt="完整的Inception网络">图中圈起来的隐藏层用于 <code>softmax</code> 输出，他们确保了即便是隐藏单元和中间层也参与特征计算，在 <code>Inception</code> 网络中起到一种调整效果，并且可以防止网络发生过拟合。<br>相关论文：<a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">Szegedy et al., 2014, Going Deeper with Convolutions</a></p>
<h2 id="使用开源的实现方案"><a href="#使用开源的实现方案" class="headerlink" title="使用开源的实现方案"></a>使用开源的实现方案</h2><p>很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，查看开源的实现方案会快很多。<br>某些网络通常都需要很长的时间来训练，而或许有人已经使用多个 <code>GPU</code>，通过庞大的数据集预先训练了这些网络，这样一来你就可以使用这些网络进行迁移学习。</p>
<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p><a href="https://muyi110.github.io/2018/08/08/03-%E6%9E%84%E5%BB%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/#more">迁移学习</a>在之前已有介绍。相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做预训练，然后转换到自己感兴趣的任务上，有助于加速开发。<br>对于已训练好的卷积神经网络，可以将所有层都看作是冻结的，只需要训练与你的 <code>Softmax</code> 层有关的参数即可。如下图所示：<img src="/images/deeplearning_ai_084.png" alt="迁移学习"><strong>冻结的层由于不需要改变和训练，可以看作一个固定函数。可以将这个固定函数存入硬盘，以便后续使用，而不必每次再使用训练集进行训练了。</strong><br>上述的做法适用于你只有一个较小的数据集。如果你有一个更大的数据集，应该冻结更少的层，然后训练后面的层。越多的数据意味着冻结越少的层，训练更多的层。如果有一个极大的数据集，你可以将开源的网络和它的权重整个当作初始化（代替随机初始化），然后训练整个网络。</p>
<h2 id="数据扩增"><a href="#数据扩增" class="headerlink" title="数据扩增"></a>数据扩增</h2><p>当数据量小时，数据扩增 ( <code>Data Augmentation</code>) 可能会有帮助。<strong>常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。</strong>其中，色彩转换是对图片的 <code>RGB</code> 通道数值进行随意增加或者减少，改变图片色调。关于 <code>PCA</code> 颜色增强可以查阅相关文献或代码。<br>在构建大型神经网络的时候，<strong>数据扩增</strong>和<strong>模型训练</strong>可以<strong>由两个或多个不同的线程并行来实现。</strong></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在模型研究或者竞赛方面，有一些方法能够有助于提升神经网络模型的性能：</p>
<ul>
<li>集成（ <code>Ensembling</code> ）：独立地训练几个神经网络，并平均输出它们的输出；</li>
<li><code>Multi-crop at test time</code>：将数据扩增应用到测试集，对结果进行平均。</li>
</ul>
<p>由于这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/08/03-构建机器学习项目/" rel="next" title="03.构建机器学习项目">
                <i class="fa fa-chevron-left"></i> 03.构建机器学习项目
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/wukong.png"
                alt="穆义" />
            
              <p class="site-author-name" itemprop="name">穆义</p>
              <p class="site-description motion-element" itemprop="description">既已无岸，不必回头，唯有向前，踏碎云霄，放肆桀骜</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络基础"><span class="nav-number">1.</span> <span class="nav-text">卷积神经网络基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#计算机视觉"><span class="nav-number">1.1.</span> <span class="nav-text">计算机视觉</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#边缘检测"><span class="nav-number">1.2.</span> <span class="nav-text">边缘检测</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更多边缘检测例子"><span class="nav-number">1.3.</span> <span class="nav-text">更多边缘检测例子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#填充-Padding"><span class="nav-number">1.4.</span> <span class="nav-text">填充 ( Padding )</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积步长-Strided-convolutions"><span class="nav-number">1.5.</span> <span class="nav-text">卷积步长 ( Strided convolutions )</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高维卷积"><span class="nav-number">1.6.</span> <span class="nav-text">高维卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#单层卷积网络-one-layer-of-a-convolutional-network"><span class="nav-number">1.7.</span> <span class="nav-text">单层卷积网络 (one layer of a convolutional network)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#简单卷积网络示例"><span class="nav-number">1.8.</span> <span class="nav-text">简单卷积网络示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#池化层"><span class="nav-number">1.9.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积神经网络示例"><span class="nav-number">1.10.</span> <span class="nav-text">卷积神经网络示例</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用卷积神经网络原因"><span class="nav-number">1.11.</span> <span class="nav-text">使用卷积神经网络原因</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度卷积网络：实例探究"><span class="nav-number">2.</span> <span class="nav-text">深度卷积网络：实例探究</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#经典网络"><span class="nav-number">2.1.</span> <span class="nav-text">经典网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LeNet-5"><span class="nav-number">2.1.1.</span> <span class="nav-text">LeNet-5</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AlexNet"><span class="nav-number">2.1.2.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG"><span class="nav-number">2.1.3.</span> <span class="nav-text">VGG</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#残差网络-Residual-Networks-ResNets"><span class="nav-number">2.2.</span> <span class="nav-text">残差网络 (Residual Networks, ResNets)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#残差网络有效的原因"><span class="nav-number">2.3.</span> <span class="nav-text">残差网络有效的原因</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-times-1-卷积"><span class="nav-number">2.4.</span> <span class="nav-text">\(1\times 1\) 卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Inception-网络"><span class="nav-number">2.5.</span> <span class="nav-text">Inception 网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#完整的-Inception-网络"><span class="nav-number">2.6.</span> <span class="nav-text">完整的 Inception 网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用开源的实现方案"><span class="nav-number">2.7.</span> <span class="nav-text">使用开源的实现方案</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#迁移学习"><span class="nav-number">2.8.</span> <span class="nav-text">迁移学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据扩增"><span class="nav-number">2.9.</span> <span class="nav-text">数据扩增</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">2.10.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">穆义</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
